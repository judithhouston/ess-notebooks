{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to start\n",
    "\n",
    "Before starting you must:\n",
    "- Have conda installed\n",
    "- `conda env create -f ess-notebooks-latest.yml python=3.7` . The yaml environment file is part of this repository.\n",
    "- fetch the data `git clone git@github.com:scipp/ess-notebooks-data.git` somewhere local \n",
    "- Generate the `dataconfig.py` file using `make_config.py` located in same directory as this notebook. In general, you simply need to point `make_config.py` to the root directory of data you cloned above. Refer to the help `make_config.py --help` for more information. \n",
    "\n",
    "Converted to use scipp and notebook from [this repository](https://github.com/scipp/ess-legacy).\n",
    "\n",
    "For Table of Contents install Jupyter extensions then reload the notebook:\n",
    "`conda install -c conda-forge jupyter_contrib_nbextensions`\n",
    "`jupyter contrib nbextension install --user`\n",
    "`jupyter nbextension enable toc2/main`\n",
    "\n",
    "# Experimental Summary\n",
    "\n",
    "This script has been developed to measure local strain ε defined as ε = ΔL/L0 in a FCC steel sample under elastic strain in a stress rig. Measured at V20, HZB, Berlin, September 2018 by Peter Kadletz.\n",
    "\n",
    "λ = 2dsinθ, where 2θ = π (transmission), edges characterise the Bragg condition and hence λ = 2d. Therefore strain is easily computed from the wavelength measurement of of a Bragg edge directly, using un-loaded vs loaded experimental runs (and reference mesurements). The known Miller indices of the crystal structure (FCC) are used to predict the wavelength where the Bragg edges should exist, which is bound by the reachable wavelength extents for the instrument. This provides an approximate region to apply a fit.  A complement error function is used to fit each Bragg edge, and a refined centre location (λ) for the edge is used in the strain measurement. Because each bragg edge can be identified individually, one can determine anisotropic strain across the unit cell in the reachable crystallographic directions. In addition the image processing allows for spacial grouping so localised effects, such as those on unconstrained edges of the sample or in necking regions of the sample can be treated seperately. The plotted outputs in the script aim to capture this.\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "import numpy as np\n",
    "from scipp.plot import plot\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from utils import wfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reduction\n",
    "\n",
    "## Load the data files and instrument geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "ds = utils.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = plot(ds[\"sample\"])\n",
    "# p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.make_static()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.neutron.instrument_view(ds[\"sample\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Converting time coordinate to TOF\n",
    "\n",
    "Use the instrument geometry and chopper cascade parameters to compute time-distance diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "v20setup = wfm.v20.setup()\n",
    "# Feed in the detector position to the instrument chopper cascade\n",
    "v20setup['info']['detector_positions'] = {\n",
    "    \"GP2\": -ds.coords['source-position'].value[2] + v20setup['info']['wfm_choppers_midpoint'] + sc.geometry.z(\n",
    "    ds.coords[\"position\"])['x', 0]['y', 0].value}\n",
    "\n",
    "frames = wfm.get_frames(instrument=v20setup, plot=True)\n",
    "frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We overlay the frame locations onto a spectrum of integrated counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "fig1, ax1 = plt.subplots()\n",
    "plot(sc.sum(sc.sum(ds[\"reference\"], 'x'), 'y'), ax=ax1)\n",
    "for i in range(len(frames[\"GP2\"][\"left_edges\"])):\n",
    "    ax1.axvspan(frames[\"GP2\"][\"left_edges\"][i], frames[\"GP2\"][\"right_edges\"][i], color=\"C{}\".format(i), alpha=0.3)\n",
    "fig1.canvas.draw_idle()\n",
    "fig1.canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the sections in the original data using value-based slicing and shift the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched = wfm.stitch(data=ds, dim=\"t\", frames=frames[\"GP2\"], nbins=256)\n",
    "stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot({\"frame{}\".format(i): sc.sum(sc.sum(sections[\"reference\"][i], 'x'), 'y')\n",
    "#       for i in range(len(sections[\"reference\"]))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stitch the data, we make a common container with a TOF axis spanning the entire range, and sum the counts from the different frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sc.sum(sc.sum(stitched, 'x'), 'y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop to relevant tof section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tof_start = 9.0e3*sc.units.us\n",
    "tof_end = 2.6e4*sc.units.us\n",
    "stitched = stitched[\"tof\", tof_start:tof_end].copy()\n",
    "plot(sc.sum(sc.sum(stitched, 'x'), 'y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transmission Masking\n",
    "\n",
    "Divides the integrated sample counts with an open beam reference. Any values > masking threshold will be masked. The adj pixels step checks for random pixels which were left unmasked or masked with all their neighbours having the same mask value. These are forced to True or false depending on their neighbour value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated = sc.sum(stitched, 'tof')\n",
    "integrated /= integrated[\"reference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking_threshold = 0.80 * sc.units.one\n",
    "\n",
    "for key in [\"sample\", \"sample_elastic\"]:\n",
    "    mask = sc.greater(integrated[key].data, masking_threshold)\n",
    "    # Apply some neighbour smoothing to the masks\n",
    "    mask = utils.operations.mask_from_adj_pixels(mask)\n",
    "    stitched[key].masks[\"non-sample-region\"] = mask\n",
    "stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sc.sum(stitched[\"sample\"], \"tof\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize by open beam\n",
    "normalized = stitched / stitched[\"reference\"]\n",
    "del normalized[\"reference\"]\n",
    "\n",
    "replacement = sc.Variable(value=0.0, variance=0.0)\n",
    "kwargs = {\"nan\": replacement, \"posinf\": replacement, \"neginf\": replacement}\n",
    "for k in normalized.keys():\n",
    "    sc.nan_to_num(normalized[k].data, out=normalized[k].data, **kwargs)\n",
    "\n",
    "plot(sc.sum(sc.sum(normalized, 'x'), 'y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength = sc.neutron.convert(normalized, \"tof\", \"wavelength\")\n",
    "\n",
    "# Rebin to common wavelength axis\n",
    "edges = sc.array(dims=[\"wavelength\"],\n",
    "                       values=np.linspace(2.0, 5.0, 119), unit=sc.units.angstrom)\n",
    "wavelength = sc.rebin(wavelength, \"wavelength\", edges)\n",
    "wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sc.sum(sc.sum(wavelength, 'x'), 'y'), grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply mean filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in wavelength:\n",
    "    wavelength[key].data = utils.operations.mean_from_adj_pixels(wavelength[key].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show difference between sample and elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(wavelength[\"sample\"] - wavelength[\"sample_elastic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted sum of the counts in the sample\n",
    "\n",
    "We use the unloaded sample as our reference, so we perform a weighted sum (using the inverse of the variances as weights) of the counts from all the pixels to increase statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances = sc.variances(wavelength[\"sample\"].data)\n",
    "# values = wavelength[\"sample\"] / variances\n",
    "# norm = sc.DataArray(data=sc.reciprocal(variances),\n",
    "#                     masks=dict(da.masks.items()))\n",
    "# sc.variances(da.data)\n",
    "sample_summed = sc.nansum(sc.nansum(wavelength[\"sample\"] / variances, 'x'), 'y') / sc.nansum(sc.nansum(sc.reciprocal(variances), 'x'), 'y')\n",
    "sample_summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sample_summed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group detector pixels to increase signal to noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength = sc.rebin(wavelength, \"x\",\n",
    "                sc.array(dims=['x'], values=np.linspace(-0.011, 0.011, 33), unit=sc.units.m))\n",
    "wavelength = sc.rebin(wavelength, \"y\",\n",
    "                sc.array(dims=['y'], values=np.linspace(-0.011, 0.011, 33), unit=sc.units.m))\n",
    "plot(wavelength[\"sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot({\"sample\": sample_summed, \"elastic\": wavelength[\"sample_elastic\"][\"x\", 16][\"y\", 16]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting\n",
    "## Calculate expected Bragg edge positions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bragg edge position, in Angstrom, taken from COD entry 9008469\n",
    "FCC_a = 3.5\n",
    "\n",
    "# These miller indices for the given unit cell yield bragg edges\n",
    "# between the maximum and minimum wavelength range.\n",
    "indices_FCC = [(1, 1, 1), (2, 0, 0), (2, 2, 0), (3, 1, 1)]\n",
    "\n",
    "Bragg_edges_FCC = utils.create_Braggedge_list(FCC_a, indices_FCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bragg-edge fitting\n",
    "\n",
    "Fit Bragg-edge peaks for the sample initially. Then take this value to find the position within a window\n",
    "for the elastic sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
