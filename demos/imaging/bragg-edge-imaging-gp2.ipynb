{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to start\n",
    "\n",
    "Before starting you must:\n",
    "- Have conda installed\n",
    "- `conda env create -f ess-notebooks-latest.yml python=3.7` . The yaml environment file is part of this repository.\n",
    "- fetch the data `git clone git@github.com:scipp/ess-notebooks-data.git` somewhere local \n",
    "- Generate the `dataconfig.py` file using `make_config.py` located in same directory as this notebook. In general, you simply need to point `make_config.py` to the root directory of data you cloned above. Refer to the help `make_config.py --help` for more information. \n",
    "\n",
    "Converted to use scipp and notebook from [this repository](https://github.com/scipp/ess-legacy).\n",
    "\n",
    "For Table of Contents install Jupyter extensions then reload the notebook:\n",
    "`conda install -c conda-forge jupyter_contrib_nbextensions`\n",
    "`jupyter contrib nbextension install --user`\n",
    "`jupyter nbextension enable toc2/main`\n",
    "\n",
    "# Experimental Summary\n",
    "\n",
    "This script has been developed to measure local strain ε defined as ε = ΔL/L0 in a FCC steel sample under elastic strain in a stress rig. Measured at V20, HZB, Berlin, September 2018 by Peter Kadletz.\n",
    "\n",
    "λ = 2dsinθ, where 2θ = π (transmission), edges characterise the Bragg condition and hence λ = 2d. Therefore strain is easily computed from the wavelength measurement of of a Bragg edge directly, using un-loaded vs loaded experimental runs (and reference mesurements). The known Miller indices of the crystal structure (FCC) are used to predict the wavelength where the Bragg edges should exist, which is bound by the reachable wavelength extents for the instrument. This provides an approximate region to apply a fit.  A complement error function is used to fit each Bragg edge, and a refined centre location (λ) for the edge is used in the strain measurement. Because each bragg edge can be identified individually, one can determine anisotropic strain across the unit cell in the reachable crystallographic directions. In addition the image processing allows for spacial grouping so localised effects, such as those on unconstrained edges of the sample or in necking regions of the sample can be treated seperately. The plotted outputs in the script aim to capture this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": true
   },
   "source": [
    "# Script setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     import scipp\n",
    "# except ImportError as e:\n",
    "#     print(\"scipp is not available in the PYTHONPATH\")\n",
    "#     raise e\n",
    "\n",
    "# try:\n",
    "#     import mantid\n",
    "# except ImportError as e:\n",
    "#     print(\"mantid is not available in the PYTHONPATH\")\n",
    "#     raise e\n",
    "\n",
    "# try:\n",
    "#     import dataconfig\n",
    "# except ImportError as e:\n",
    "#     print(\n",
    "#         \"dataconfig is not available. Make sure you have generated it with `make_config.py`.\"\n",
    "#     )\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating point precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "float_type = np.float32\n",
    "\n",
    "\n",
    "# Helper to determine scipp dtype from np dtype\n",
    "def scipp_dtype(dtype):\n",
    "    return sc.Variable(value=0, dtype=dtype).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set input and output dirs\n",
    "\n",
    "If your input directory has a different structure this is the cell to modify. \n",
    "Additionally the output directory can be renamed too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lets get everything set up\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import scipp as sc\n",
    "import numpy as np\n",
    "from scipp.plot import plot\n",
    "from dress import wfm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ess.v20.imaging as imaging\n",
    "import ess.v20.imaging.operations as operations\n",
    "import dataconfig\n",
    "from scipy import ndimage, signal\n",
    "\n",
    "local_data_path = os.path.join('ess', 'v20', 'imaging', 'gp2-stress-experiments')\n",
    "data_dir = os.path.join(dataconfig.data_root, local_data_path)\n",
    "output_dir = os.path.join(dataconfig.data_root, 'output')\n",
    "instrument_file = os.path.join(data_dir, 'V20_Definition_GP2.xml')\n",
    "\n",
    "tofs_path = os.path.join(data_dir, 'GP2_Stress_time_values.txt')\n",
    "raw_data_dir = os.path.join(data_dir)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    raise FileNotFoundError(\"The following data directory does not exist,\"\n",
    "                            f\" check your make_config.py:\\n{data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = sc.Dataset()\n",
    "sc.compat.mantid.load_component_info(geometry, instrument_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": true
   },
   "source": [
    "## Reduction Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Customisable Options:\n",
    "\n",
    "# # defining grouping of 2D detector pixels\n",
    "# nx_source = 324\n",
    "# ny_source = 324\n",
    "# grouping_number = 27\n",
    "# nx_target = grouping_number\n",
    "# ny_target = grouping_number\n",
    "\n",
    "# bin_width = (64 * 2.5)  # μS\n",
    "\n",
    "# # Rebin regions for each of the 5 WFM frames. Values are in detector time : μS\n",
    "# # in the format of [bin-start, bin-end, bin width].\n",
    "# # used to crop each image, before stitching them together\n",
    "# frame_parameters = [{\n",
    "#     \"start\": 15450,\n",
    "#     \"stop\": 22942,\n",
    "#     \"step\": bin_width\n",
    "# }, {\n",
    "#     \"start\": 24800,\n",
    "#     \"stop\": 32052,\n",
    "#     \"step\": bin_width\n",
    "# }, {\n",
    "#     \"start\": 33791,\n",
    "#     \"stop\": 40084,\n",
    "#     \"step\": bin_width\n",
    "# }, {\n",
    "#     \"start\": 41763,\n",
    "#     \"stop\": 47457,\n",
    "#     \"step\": bin_width\n",
    "# }, {\n",
    "#     \"start\": 49315,\n",
    "#     \"stop\": 54500,\n",
    "#     \"step\": bin_width\n",
    "# }, {\n",
    "#     \"start\": 56500,\n",
    "#     \"stop\": 58360,\n",
    "#     \"step\": bin_width\n",
    "# }]\n",
    "\n",
    "# # Used to rebin the summed frame in order to\n",
    "# # cut off frames that contain no data\n",
    "# rebin_parameters = {\"start\": 8550, \"stop\": 26000, \"step\": bin_width}\n",
    "\n",
    "# # Used to shift the cropped frames so that their bins overlap\n",
    "# # before summing them together into a single frame\n",
    "# frame_shift_increments = [-6630, -2420, -2253, -2095, -1946, -1810]\n",
    "# frame_shift_increments = [float(i)\n",
    "#                           for i in frame_shift_increments]  # Work around #1114\n",
    "\n",
    "# Pulse references\n",
    "pulse_number_reference = 1.0 / 770956\n",
    "pulse_number_sample = 1.0 / 1280381\n",
    "pulse_number_sample_elastic = 1.0 / 2416839\n",
    "pulse_number_sample_plastic = 1.0 / 2614343\n",
    "\n",
    "# units of transmission, all pixels with transmission higher masking threshold are masked\n",
    "masking_threshold = 0.80\n",
    "\n",
    "# Toggles outputting masked and sliced tiff stacks\n",
    "output_tiff_stack = False\n",
    "\n",
    "# Experiment Metadata\n",
    "measurement_number = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reduction\n",
    "\n",
    "## Load the data files and instrument geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# Load time bins from 1D text file\n",
    "ds = sc.Dataset()\n",
    "ds.coords[\"t\"] = sc.Variable([\"t\"],\n",
    "                             unit=sc.units.us,\n",
    "                             values=imaging.read_x_values(tofs_path, skiprows=1, usecols=1, delimiter='\\t'),)\n",
    "ds.coords[\"t\"] *= 1e3\n",
    "\n",
    "# Load tiff stack\n",
    "def load_and_scale(folder_name, scale_factor):\n",
    "    to_load = os.path.join(raw_data_dir, folder_name)\n",
    "    variable = imaging.tiffs_to_variable(to_load, dtype=float_type)\n",
    "    variable *= scale_factor\n",
    "    return variable\n",
    "\n",
    "ds[\"reference\"] = load_and_scale(folder_name=\"R825-open-beam\",\n",
    "                                 scale_factor=pulse_number_reference)\n",
    "ds[\"sample\"] = load_and_scale(folder_name=\"R825\",\n",
    "                              scale_factor=pulse_number_sample)\n",
    "ds[\"sample_elastic\"] = load_and_scale(folder_name=\"R825-600-Mpa\",\n",
    "                                      scale_factor=pulse_number_sample_elastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = sc.Dataset()\n",
    "sc.compat.mantid.load_component_info(geometry, instrument_file)\n",
    "geom = sc.Dataset(coords={\"sample-position\": geometry.coords[\"sample-position\"],\n",
    "                          \"source-position\": geometry.coords[\"source-position\"]})\n",
    "geom.coords[\"position\"] = sc.reshape(geometry.coords['position'], dims=['y', 'x'],\n",
    "                                     shape=tuple(ds[\"sample\"][\"t\", 0].shape))\n",
    "geom.coords[\"x\"] = sc.geometry.x(geom.coords[\"position\"])[\"y\", 0]\n",
    "geom.coords[\"y\"] = sc.geometry.y(geom.coords[\"position\"])[\"x\", 0]\n",
    "ds = sc.merge(ds, geom)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ds[\"sample\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Converting time coordinate to TOF\n",
    "\n",
    "Use the instrument geometry and chopper cascade parameters to compute time-distance diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "v20setup = wfm.v20.setup()\n",
    "v20setup['info']['detector_positions'] = {\n",
    "    \"GP2\": -ds.coords['source-position'].value[2] + v20setup['info']['wfm_choppers_midpoint'] + sc.geometry.z(\n",
    "    geom.coords[\"position\"])['x', 0]['y', 0].value}\n",
    "\n",
    "frames = wfm.get_frames(instrument=v20setup, plot=True)\n",
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "fig1, ax1 = plt.subplots()\n",
    "plot(sc.sum(sc.sum(ds[\"reference\"], 'x'), 'y'), ax=ax1)\n",
    "for i in range(len(frames[\"GP2\"][\"left_edges\"])):\n",
    "    ax1.axvspan(frames[\"GP2\"][\"left_edges\"][i], frames[\"GP2\"][\"right_edges\"][i], color=\"C{}\".format(i), alpha=0.3)\n",
    "fig1.canvas.draw_idle()\n",
    "fig1.canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the sections in the original data using value-based slicing and shift the coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = {}\n",
    "for key in ds:\n",
    "    sections[key] = []\n",
    "    for i in range(len(frames[\"GP2\"][\"left_edges\"])):\n",
    "        section = ds[key][\"t\",\n",
    "                             frames[\"GP2\"][\"left_edges\"][i]*sc.units.us:frames[\"GP2\"][\"right_edges\"][i]*sc.units.us].copy()\n",
    "        section.coords[\"t\"] += frames[\"GP2\"][\"shifts\"][i]*sc.units.us\n",
    "        section.rename_dims({'t': 'tof'})\n",
    "        sections[key].append(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot({\"frame{}\".format(i): sc.sum(sc.sum(sections[\"reference\"][i], 'x'), 'y')\n",
    "      for i in range(len(sections[\"reference\"]))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stitch the data, we make a common container with a TOF axis spanning the entire range, and sum the counts from the different frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntof = 512\n",
    "stitched = sc.Dataset()\n",
    "stitched.coords[\"tof\"] = sc.Variable([\"tof\"],\n",
    "                             unit=sc.units.us,\n",
    "                             values=np.linspace(9.0e3, 5.0e4, ntof + 1))\n",
    "for key in ds.coords:\n",
    "    if key != \"t\":\n",
    "        stitched.coords[key] = ds.coords[key]\n",
    "# Make empty data container\n",
    "for key in ds:\n",
    "    stitched[key] = sc.zeros(dims=[\"tof\", \"y\", \"x\"], shape=[ntof] + ds.coords[\"position\"].shape,\n",
    "                                 variances=True, unit=sc.units.counts)\n",
    "# Sum counts from different frames\n",
    "for key in sections:\n",
    "    for sec in sections[key]:\n",
    "        stitched[key] += sc.rebin(sec, 'tof', stitched.coords[\"tof\"])\n",
    "stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sc.sum(sc.sum(stitched, 'x'), 'y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize by open beam\n",
    "normalized = stitched / stitched[\"reference\"]\n",
    "del normalized[\"reference\"]\n",
    "\n",
    "replacement = sc.Variable(value=0.0, variance=0.0)\n",
    "kwargs = {\"nan\": replacement, \"posinf\": replacement, \"neginf\": replacement}\n",
    "for k in normalized.keys():\n",
    "    sc.nan_to_num(normalized[k].data, out=normalized[k].data, **kwargs)\n",
    "\n",
    "plot(sc.sum(sc.sum(normalized, 'x'), 'y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength = sc.neutron.convert(normalized, \"tof\", \"wavelength\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(wavelength[\"sample\"], axes={'x': \"wavelength\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
