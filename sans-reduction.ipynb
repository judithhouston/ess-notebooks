{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to start\n",
    "\n",
    "Before starting you must:\n",
    "- Have conda installed\n",
    "- `conda env create -f ess-notebooks-latest.yml python=3.7` . The yaml environment file is part of this repository.\n",
    "- fetch the data `git clone git@github.com:scipp/ess-notebooks-data.git` somewhere local \n",
    "- Generate the `dataconfig.py` file using `make_config.py` located in same directory as this notebook. In general, you simply need to point `make_config.py` to the root directory of data you cloned above. Refer to the help `make_config.py --help` for more information. \n",
    "\n",
    "Converted to use scipp and notebook from [this repository](https://github.com/scipp/ess-legacy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "import numpy as np\n",
    "import os\n",
    "import dataconfig # run make_config.py to create this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin_centers(d, dim):\n",
    "    edges = d.coords[dim].copy()\n",
    "    del d.coords[dim]\n",
    "    d.coords[dim] = 0.5 * (edges[dim, 1:] + edges[dim, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin_edges(d, dim):\n",
    "    centers = d.coords[dim].copy()\n",
    "    del d.coords[dim]\n",
    "    first = 1.5*centers[dim, 0] - 0.5*centers[dim, 1]\n",
    "    last = 1.5*centers[dim, -1] - 0.5*centers[dim, -2]\n",
    "    bulk = 0.5 * (centers[dim, 1:] + centers[dim, :-1])\n",
    "    edges = sc.concatenate(first, bulk, dim)\n",
    "    edges = sc.concatenate(edges, last, dim)\n",
    "    d.coords[dim] = edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_bins(data, dim, edges):\n",
    "    data = data.copy()\n",
    "    to_bin_edges(data, dim)\n",
    "    bin_width = data.coords[dim][dim,1:] - data.coords[dim][dim,:-1]\n",
    "    bin_width.unit = sc.units.one\n",
    "    data *= bin_width\n",
    "    data = sc.rebin(data, dim, edges)\n",
    "    bin_width = edges[dim,1:] - edges[dim,:-1]\n",
    "    bin_width.unit = sc.units.one\n",
    "    data /= bin_width\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and set variables  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(dataconfig.data_root, 'ess', 'loki', 'tube-calibration')\n",
    "direct_beam_file = 'DirectBeam_20feb_full_v3.dat'\n",
    "moderator_file = 'ModeratorStdDev_TS2_SANS_LETexptl_07Aug2015.txt'\n",
    "sample_run_number = 49338\n",
    "sample_transmission_run_number = 49339\n",
    "background_run_number = 49334\n",
    "background_transmission_run_number = 49335\n",
    "l_collimation = sc.Variable(value=5.0, unit=sc.units.m)\n",
    "r2 = sc.Variable(value=4.0824829046386295/1000, unit=sc.units.m) # sample aperture radius\n",
    "r1 = sc.Variable(value=14.433756729740645/1000, unit=sc.units.m) # source aperture radius\n",
    "dr = sc.Variable(value=8.0/1000, unit=sc.units.m) # virtual ring width on detector\n",
    "    \n",
    "def load_larmor(run_number):\n",
    "    return sc.neutron.load(filename=f'{path}/LARMOR000{run_number}.nxs')\n",
    "\n",
    "def load_rkh(filename):\n",
    "    return sc.neutron.load(\n",
    "           filename=filename,\n",
    "           mantid_alg='LoadRKH',\n",
    "           mantid_args={'FirstColumnValue':'Wavelength'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trans = load_larmor(sample_transmission_run_number)\n",
    "sample = load_larmor(sample_run_number)\n",
    "background_trans = load_larmor(background_transmission_run_number)\n",
    "background = load_larmor(background_run_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add geometry information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = sample.coords['position'].dtype\n",
    "sample_pos_offset = sc.Variable(value=[0.0, 0.0, 0.30530], unit=sc.units.m, dtype=dtype)\n",
    "bench_pos_offset = sc.Variable(value=[0.0, 0.001, 0.0], unit=sc.units.m, dtype=dtype)\n",
    "for item in [sample, sample_trans, background, background_trans]:\n",
    "    item.coords['sample-position'] += sample_pos_offset\n",
    "    item.coords['position'] += bench_pos_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set wavelength binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_bins = sc.Variable(\n",
    "    dims=['wavelength'],\n",
    "    unit=sc.units.angstrom,\n",
    "    values=np.geomspace(0.9, 13.5, num=110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_masks(data):\n",
    "    tof = data.coords['tof']\n",
    "    data.masks['bins'] = sc.less(tof['tof',1:], 1500.0 * sc.units.us) | \\\n",
    "                         (sc.greater(tof['tof',:-1], 17500.0 * sc.units.us) & \\\n",
    "                          sc.less(tof['tof',1:], 19000.0 * sc.units.us))\n",
    "    pos = sc.neutron.position(data)\n",
    "    x = sc.geometry.x(pos)\n",
    "    y = sc.geometry.y(pos)\n",
    "    data.masks['beam-stop'] = sc.less(sc.sqrt(x*x+y*y), 0.045 * sc.units.m)\n",
    "    data.masks['tube-ends'] = sc.greater(sc.abs(x), 0.36 * sc.units.m) # roughly all det IDs listed in original\n",
    "    #MaskDetectorsInShape(Workspace=maskWs, ShapeXML=self.maskingPlaneXML) # irrelevant tiny wedge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_mean(data, dim, begin, end):\n",
    "    coord = data.coords[dim]\n",
    "    assert (coord.unit == begin.unit) and (coord.unit == end.unit)\n",
    "    i = np.searchsorted(coord, begin.value)\n",
    "    j = np.searchsorted(coord, end.value) + 1\n",
    "    return data - sc.mean(data[dim, i:j], dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transmission_fraction(incident_beam, transmission):\n",
    "    # Approximation based on equations in CalculateTransmission documentation\n",
    "    # TODO proper implementation of mantid.CalculateTransmission\n",
    "    return (transmission / transmission) * (incident_beam / incident_beam)\n",
    "    #CalculateTransmission(SampleRunWorkspace=transWsTmp,\n",
    "    #                      DirectRunWorkspace=transWsTmp,\n",
    "    #                      OutputWorkspace=outWsName,\n",
    "    #                      IncidentBeamMonitor=1,\n",
    "    #                      TransmissionMonitor=4, RebinParams='0.9,-0.025,13.5',\n",
    "    #                      FitMethod='Polynomial',\n",
    "    #                      PolynomialOrder=3, OutputUnfittedData=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_monitor_background(data, begin, end):\n",
    "    background = background_mean(data, 'tof', begin, end)\n",
    "    del background.coords['sample-position'] # ensure unit conversion treats this a monitor\n",
    "    background = sc.neutron.convert(background, 'tof', 'wavelength')\n",
    "    background = sc.rebin(background, 'wavelength', wavelength_bins)\n",
    "    return background\n",
    "\n",
    "def setup_transmission(data):\n",
    "    incident_beam = extract_monitor_background(data['spectrum', 0], 40000.0*sc.units.us, 99000.0*sc.units.us)\n",
    "    transmission = extract_monitor_background(data['spectrum', 3], 88000.0*sc.units.us, 98000.0*sc.units.us)\n",
    "    return transmission_fraction(incident_beam, transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solid_angle(data):\n",
    "    # TODO proper solid angle\n",
    "    # [0.0117188,0.0075,0.0075] bounding box size\n",
    "    pixel_size = 0.0075 * sc.units.m \n",
    "    pixel_length = 0.0117188 * sc.units.m\n",
    "    L2 = sc.neutron.l2(data)\n",
    "    return (pixel_size * pixel_length) / (L2 * L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_resolution(lam_edges, moderator, d, l_collimation, r1, r2, dr):\n",
    "    moderator = sc.rebin(moderator, 'wavelength', lam_edges)\n",
    "    \n",
    "    d_lam = lam_edges['wavelength', 1:] - lam_edges['wavelength', :-1] # bin widths\n",
    "    lam = 0.5 * (lam_edges['wavelength', 1:] + lam_edges['wavelength', :-1]) # bin centres\n",
    "    \n",
    "    l2 = sc.neutron.l2(d)\n",
    "    theta = sc.neutron.scattering_angle(d)  \n",
    "    inv_l3 = (l_collimation + l2) / (l_collimation * l2)\n",
    "    \n",
    "    # Terms in Mildner and Carpenter equation.\n",
    "    # See https://docs.mantidproject.org/nightly/algorithms/TOFSANSResolutionByPixel-v1.html\n",
    "    a1 = (r1/l_collimation)*(r1/l_collimation) * 3.0\n",
    "    a2 = (r2*inv_l3)*(r2*inv_l3) * 3.0\n",
    "    a3 = (dr/l2) * (dr/l2) \n",
    "    q_sq = 4.0 * np.pi * sc.sin(theta) * sc.reciprocal(lam) # keep in wav dim to prevent broadcast\n",
    "    q_sq *= q_sq\n",
    "    \n",
    "    tof = moderator.data.copy()\n",
    "    tof.variances = None # shortcoming of Mantid or Mantid converter?\n",
    "    tof.rename_dims({'wavelength':'tof'}) # TODO overly restrictive check in convert (rename)\n",
    "    tof.unit = sc.units.us\n",
    "    mod = sc.Dataset(coords={\n",
    "      'tof':tof,\n",
    "      'position':sample.coords['position'],\n",
    "      'source_position':sample.coords['source_position'],\n",
    "      'sample_position':sample.coords['sample_position']})\n",
    "    s = sc.neutron.convert(mod, 'tof', 'wavelength').coords['wavelength']\n",
    "    \n",
    "    std_dev_lam_sq = (d_lam * d_lam)/12 + s * s\n",
    "    std_dev_lam_sq *= sc.reciprocal(lam * lam)\n",
    "    f = (4 * np.pi * np.pi) * sc.reciprocal(12 * lam * lam)\n",
    "   \n",
    "    return sc.DataArray(f * (a1 + a2 + a3) + (q_sq * std_dev_lam_sq),\n",
    "                        coords={'wavelength':lam, 'spectrum':d.coords['spectrum'].copy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1d(data, transmission, l_collimation, r1, r2, dr, wavelength_bands=None):\n",
    "    transmission = setup_transmission(transmission)\n",
    "    data = data.copy()\n",
    "    apply_masks(data)\n",
    "    data = sc.neutron.convert(data, 'tof', 'wavelength', out=data)\n",
    "    data = sc.rebin(data, 'wavelength', wavelength_bins)\n",
    "    \n",
    "\n",
    "    monitor = data.coords['monitor1'].value\n",
    "    monitor = background_mean(monitor, 'tof', 40000.0*sc.units.us, 99000.0*sc.units.us)\n",
    "    monitor = sc.neutron.convert(monitor, 'tof', 'wavelength', out=monitor)\n",
    "    monitor = sc.rebin(monitor, 'wavelength', wavelength_bins)\n",
    "\n",
    "    # this factor seems to be a fudge factor. Explanation pending.\n",
    "    data *= 100.0 / 176.71458676442586\n",
    "\n",
    "    # Setup direct beam and normalise to monitor. I.e. adjust for efficiency of detector across the wavelengths.\n",
    "    direct_beam = load_rkh(filename=f'{path}/{direct_beam_file}')\n",
    "    # This would work assuming that there is a least one wavelength point per bin\n",
    "    #direct_beam = sc.groupby(direct_beam, 'wavelength', bins=monitor.coords['wavelength']).mean('wavelength')\n",
    "    direct_beam = map_to_bins(direct_beam, 'wavelength', monitor.coords['wavelength'])\n",
    "    direct_beam = monitor * transmission * direct_beam\n",
    "\n",
    "    # Estimate qresolution function\n",
    "    moderator = load_rkh(filename=f'{path}/{moderator_file}')\n",
    "    to_bin_edges(moderator, 'wavelength')\n",
    "    \n",
    "    q_bins = sc.Variable(\n",
    "        dims=['Q'],\n",
    "        unit=sc.units.one/sc.units.angstrom,\n",
    "        values=np.geomspace(0.008, 0.6, num=55))\n",
    "    \n",
    "    d = sc.Dataset({'data':data, 'norm':solid_angle(data)*direct_beam})\n",
    "    \n",
    "    if wavelength_bands is None:\n",
    "\n",
    "        #dq_sq = q_resolution(_d.coords['wavelength'], moderator, d, l_collimation, r1, r2, dr)\n",
    "        to_bin_centers(d, 'wavelength')\n",
    "        d = sc.neutron.convert(d, 'wavelength', 'Q', out=d) # TODO no gravity yet\n",
    "    \n",
    "        d = sc.histogram(d, q_bins)\n",
    "        d = sc.sum(d, 'spectrum')\n",
    "        I = d['data']/d['norm']\n",
    "    else:\n",
    "       \n",
    "        # Reduce by wavelength slice\n",
    "        n_band = int(wavelength_bands)\n",
    "        high = sc.nanmax(wavelength_bins)\n",
    "        low = sc.nanmin(wavelength_bins)\n",
    "        step = (high.value-low.value)/n_band\n",
    "        range_edges = np.arange(low.value, high.value + step, step)\n",
    "        slices = [slice(sc.Variable(value=i, unit=sc.units.angstrom), sc.Variable(value=j, unit=sc.units.angstrom)) for i, j in zip(range_edges[:-1:], range_edges[1::])]\n",
    "        bands = None\n",
    "        for slc in slices:\n",
    "            _d = d['wavelength', slc].copy()\n",
    "            to_bin_centers(_d, 'wavelength')\n",
    "            _d = sc.neutron.convert(_d, 'wavelength', 'Q', out=_d) # TODO no gravity yet\n",
    "            #dq_sq = q_resolution(_d.coords['wavelength'], moderator, d, l_collimation, r1, r2, dr)\n",
    "            band = sc.histogram(_d, q_bins) # TODO fix scipp to avoid need for copy\n",
    "            band = sc.sum(band, 'spectrum')\n",
    "            bands = sc.concatenate(bands, band, 'wavelength') if bands is not None else band\n",
    "        bands.coords['wavelength'] = sc.Variable(['wavelength'], values=range_edges, unit=sc.units.angstrom)\n",
    "        I = bands['data']/bands['norm']\n",
    "\n",
    "    return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1D reduction single wavelength band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_q1d = q1d(data=sample, transmission=sample_trans, \n",
    "                 l_collimation=l_collimation, r1=r1, r2=r2, dr=dr, wavelength_bands=None)\n",
    "background_q1d = q1d(data=background, transmission=background_trans,\n",
    "                     l_collimation=l_collimation, r1=r1, r2=r2, dr=dr,  wavelength_bands=None)\n",
    "reduced = sample_q1d - background_q1d\n",
    "\n",
    "reduced.coords['UserFile'] = sc.Variable(\n",
    "    value='USER_Raspino_191E_BCSLarmor_24Feb2020_v1.txt')\n",
    "reduced.coords['Transmission'] = sc.Variable(\n",
    "    value=f'{sample_transmission_run_number}_trans_sample_0.9_13.5_unfitted')\n",
    "reduced.coords['TransmissionCan'] = sc.Variable(\n",
    "    value=f'{background_transmission_run_number}_trans_can_0.9_13.5_unfitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to Mantid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude-from-export\n",
    "from scipp.plot import plot\n",
    "values, stddev = np.loadtxt(os.path.join(path, \"mantid_reduced.txt\"))\n",
    "q = np.loadtxt(os.path.join(path, \"mantid_reduced_q.txt\"))\n",
    "\n",
    "mantid = sc.DataArray(data=sc.Variable(['Q'],\n",
    "                                       values=values,\n",
    "                                       variances=stddev*stddev),\n",
    "                      coords={'Q': sc.Variable(['Q'], unit=sc.units.one/sc.units.angstrom, values=q)})\n",
    "mantid = sc.rebin(mantid, 'Q', reduced.coords['Q'])\n",
    "\n",
    "ds = sc.Dataset({'mantid': mantid, 'scipp': reduced})\n",
    "plot(ds, scale={'y': 'log'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce in wavelength bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_q1d = q1d(data=sample,l_collimation=l_collimation, r1=r1, r2=r2, dr=dr, transmission=sample_trans, wavelength_bands=7)\n",
    "background_q1d = q1d(data=background, l_collimation=l_collimation, r1=r1, r2=r2, dr=dr, transmission=background_trans, wavelength_bands=7)\n",
    "reduced = sample_q1d - background_q1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude-from-export\n",
    "plot(sc.collapse(reduced, 'Q'), scale={'y': 'log'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude-from-export\n",
    "plot(reduced, scale={'x': 'log', 'y': 'log'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
